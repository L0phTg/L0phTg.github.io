<!DOCTYPE html>
<html lang="">
<head>

  <meta charset="utf-8" />

  
  <title>使用docker搭建spark集群</title>

  
  
  <link href="//cdn.jsdelivr.net" rel="dns-prefetch">
  <link href="//cdnjs.cloudflare.com" rel="dns-prefetch">
  
  <link href="//at.alicdn.com" rel="dns-prefetch">
  
  <link href="//fonts.googleapis.com" rel="dns-prefetch">
  <link href="//fonts.gstatic.com" rel="dns-prefetch">
  
  
  
  
  

  

  
  <meta name="author" content="L0phTg">
  <meta name="description" content="运行环境:
 vmware workstation ubuntu18.04  创建了三个docker容器，分别为master、slave1、slave2：
   名称 ip hadoop/spark用户名     master 172.17.0.2 spark   slave1 172.17.0.3 spark   slave2 172.17.0.4 spark    三个容器都通过useradd创建了用户名为spark的用户，来配置集群大数据环境的用户。
">

  
  
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@gohugoio">
    <meta name="twitter:title" content="使用docker搭建spark集群">
    <meta name="twitter:description" content="运行环境:
 vmware workstation ubuntu18.04  创建了三个docker容器，分别为master、slave1、slave2：
   名称 ip hadoop/spark用户名     master 172.17.0.2 spark   slave1 172.17.0.3 spark   slave2 172.17.0.4 spark    三个容器都通过useradd创建了用户名为spark的用户，来配置集群大数据环境的用户。
">
    <meta name="twitter:image" content="/images/avatar.png">
  

  
  <meta property="og:type" content="article">
  <meta property="og:title" content="使用docker搭建spark集群">
  <meta property="og:description" content="运行环境:
 vmware workstation ubuntu18.04  创建了三个docker容器，分别为master、slave1、slave2：
   名称 ip hadoop/spark用户名     master 172.17.0.2 spark   slave1 172.17.0.3 spark   slave2 172.17.0.4 spark    三个容器都通过useradd创建了用户名为spark的用户，来配置集群大数据环境的用户。
">
  <meta property="og:url" content="http://L0phTg.top/post/bigdata/%E4%BD%BF%E7%94%A8docker%E6%90%AD%E5%BB%BAspark%E9%9B%86%E7%BE%A4/">
  <meta property="og:image" content="/images/avatar.png">




<meta name="generator" content="Hugo 0.61.0">


<link rel="canonical" href="http://L0phTg.top/post/bigdata/%E4%BD%BF%E7%94%A8docker%E6%90%AD%E5%BB%BAspark%E9%9B%86%E7%BE%A4/">

<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="format-detection" content="telephone=no,email=no,adress=no">
<meta http-equiv="Cache-Control" content="no-transform">


<meta name="robots" content="index,follow">
<meta name="referrer" content="origin-when-cross-origin">







<meta name="theme-color" content="#02b875">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<meta name="apple-mobile-web-app-title" content="L0phTg&#39;s Blog">
<meta name="msapplication-tooltip" content="L0phTg&#39;s Blog">
<meta name='msapplication-navbutton-color' content="#02b875">
<meta name="msapplication-TileColor" content="#02b875">
<meta name="msapplication-TileImage" content="/icons/icon-144x144.png">
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/icons/icon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/icons/icon-32x32.png">
<link rel="icon" sizes="192x192" href="/icons/icon-192x192.png">
<link rel="apple-touch-icon" href="/icons/icon-152x152.png">
<link rel="manifest" href="/manifest.json">


<link rel="preload" href="/styles/main-rendered.min.css" as="style">


<link rel="preload" href="https://fonts.googleapis.com/css?family=Lobster" as="style">
<link rel="preload" href="/images/avatar.png" as="image">
<link rel="preload" href="/images/grey-prism.svg" as="image">


<style>
  body {
    background: rgb(244, 243, 241) url('/images/grey-prism.svg') repeat fixed;
  }
</style>
<link rel="stylesheet" href="/styles/main-rendered.min.css">


<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lobster">



<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.2/dist/medium-zoom.min.js"></script>




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video-js.min.css">




<link rel="stylesheet" href="/css/styles/dracula.css">




  
  
<!--[if lte IE 8]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/videojs-ie8@1.1.2/dist/videojs-ie8.min.js"></script>
<![endif]-->

<!--[if lte IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/eligrey-classlist-js-polyfill@1.2.20180112/classList.min.js"></script>
<![endif]-->


  

  <script src="/js/highlight.pack.js"></script>


<script>hljs.initHighlightingOnLoad();</script>
<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script> mermaid.initialize({ startOnLoad: true });</script>

</head>
  <body>
    <div class="suspension">
      <a role="button" aria-label="Go to top" title="Go to top" class="to-top is-hide"><span class="icon icon-up" aria-hidden="true"></span></a>
      
        
      
    </div>
    
    
    
  
  <header class="site-header">
  <a href="http://L0phTg.top/"><img class="avatar" src="/images/avatar.png" alt="Avatar"></a>
  
  <h2 class="title"><a href="http://L0phTg.top/">L0phTg&#39;s Blog</a></h2>
  
  <p class="subtitle">~  读万卷书 &amp; 行万里路 ~</p>
  <button class="menu-toggle" type="button" aria-label="Main Menu" aria-expanded="false" tab-index="0">
    <span class="icon icon-menu" aria-hidden="true"></span>
  </button>

  <nav class="site-menu collapsed">
    <h2 class="offscreen">Main Menu</h2>
    <ul class="menu-list">
      
      
      
      
        <li class="menu-item
          
          
           is-active">
          <a href="/">Home</a>
        </li>
      
        <li class="menu-item
          
          
          ">
          <a href="/post/">Archives</a>
        </li>
      
        <li class="menu-item
          
          
          ">
          <a href="/tags/">Tags</a>
        </li>
      
        <li class="menu-item
          
          
          ">
          <a href="/about/">About</a>
        </li>
      
    </ul>
  </nav>
 
  <nav class="social-menu collapsed">
    <h2 class="offscreen">Social Networks</h2>
    <ul class="social-list"></ul>
  </nav>
</header>

  <section class="main post-detail">
    <header class="post-header">
      <h1 class="post-title">使用docker搭建spark集群</h1>
      <p class="post-meta">@L0phTg · Mar 3, 2021 · 3 min read</p>
      
    </header>
     
     
<div class="post-toc" id="post-toc">
  
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#docker-ce">安装docker-ce</a></li>
    <li><a href="#docker-1">配置docker仓库源</a></li>
    <li><a href="#ubuntu">获得ubuntu镜像</a></li>
  </ul>

  <ul>
    <li><a href="#heading-1">创建并启动容器</a></li>
    <li><a href="#hadoopspark">容器中安装hadoop、spark</a></li>
  </ul>

  <ul>
    <li><a href="#hdfs">hdfs</a></li>
    <li><a href="#yarn">yarn</a></li>
    <li><a href="#spark">spark</a></li>
  </ul>

  <ul>
    <li><a href="#ubuntu-1">配置ubuntu源</a></li>
    <li><a href="#docker-2">docker命令</a></li>
    <li><a href="#linux">linux操作</a></li>
  </ul>
</nav>
  </div>
</div>

     
    <article class="post-content"><p>运行环境:</p>
<ul>
<li>vmware workstation</li>
<li>ubuntu18.04</li>
</ul>
<p>创建了三个docker容器，分别为master、slave1、slave2：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>ip</th>
<th>hadoop/spark用户名</th>
</tr>
</thead>
<tbody>
<tr>
<td>master</td>
<td>172.17.0.2</td>
<td>spark</td>
</tr>
<tr>
<td>slave1</td>
<td>172.17.0.3</td>
<td>spark</td>
</tr>
<tr>
<td>slave2</td>
<td>172.17.0.4</td>
<td>spark</td>
</tr>
</tbody>
</table>
<p>三个容器都通过useradd创建了用户名为spark的用户，来配置集群大数据环境的用户。</p>
<h1 id="docker">Docker安装</h1>
<h2 id="docker-ce">安装docker-ce</h2>
<p>安装docker-ce：参考：https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e">#安装依赖</span>
$sudo apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common
<span style="color:#75715e"># 信任Docker的GPG公钥</span>
curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -
<span style="color:#75715e"># 添加软件仓库</span>
sudo add-apt-repository <span style="color:#ae81ff">\</span>
   <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">deb [arch=amd64] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/debian \
</span><span style="color:#e6db74">   </span><span style="color:#66d9ef">$(</span>lsb_release -cs<span style="color:#66d9ef">)</span><span style="color:#e6db74"> \
</span><span style="color:#e6db74">   stable</span><span style="color:#e6db74">&#34;</span>
<span style="color:#75715e"># 安装</span>
sudo apt-get update
sudo apt-get install docker-ce

sudo systemctl start docker <span style="color:#75715e"># 启动docker服务</span>
sudo systemctl enable docker <span style="color:#75715e"># 设置开机自启</span>
</code></pre></div><h2 id="docker-1">配置docker仓库源</h2>
<p><code>/etc/docker/daemon.json</code>：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-json" data-lang="json">{
    <span style="color:#f92672">&#34;registry-mirrors&#34;</span>: [
         <span style="color:#e6db74">&#34;https://registry.docker-cn.com&#34;</span>
    ]
}
</code></pre></div><p>之后重新加载daemon和重启docker：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$sudo systemctl daemon-reload
$sudo systemctl restart docker
</code></pre></div><h2 id="ubuntu">获得ubuntu镜像</h2>
<p>因为我的主机系统是ubuntu18.04，所以需要pull ubuntu18.04的镜像</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$sudo docker pull ubuntu:18.04
18.04: Pulling from library/ubuntu
d519e2592276: Pull complete 
d22d2dfcfa9c: Pull complete 
b3afe92c540b: Pull complete 
Digest: sha256:ea188fdc5be9b25ca048f1e882b33f1bc763fb976a8a4fea446b38ed0efcbeba
Status: Downloaded newer image <span style="color:#66d9ef">for</span> ubuntu:18.04
docker.io/library/ubuntu:18.04
$ 
</code></pre></div><h1 id="heading">容器操作</h1>
<h2 id="heading-1">创建并启动容器</h2>
<p><strong>以slave1为例，说明创建容器和配置容器的内容和流程，master和slave2同slave1</strong>。</p>
<p>根据ubuntu18.04创建容器，并命名为slave1</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">ubuntu# docker run -itd --name slave1 ubuntu:18.04       <span style="color:#75715e">#还可以指定很多参数、例如ip、hostname等，参照docker命令语法</span>
c7f88304681bc8a600091911bd57d5f63f5eb03d8f3baeda464aa2b1d304d8f0
ubuntu# docker exec -it slave1 bash
root@c7f88304681b:/# 
</code></pre></div><p>安装一些必备软件(默认docker容器中没有携带sudo、ifconfig、vim等命令和应用)：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">root@c7f88304681b:/# passwd                <span style="color:#75715e"># 配置root密码</span>
Enter new UNIX password:slave1root 
Retype new UNIX password:slave1root
passwd: password updated successfully
root@c7f88304681b:/# apt update
root@c7f88304681b:/# apt install vim wget net-tools iputils-ping ssh sudo
</code></pre></div><p>新建用户spark、和用户组spark、并为spark用户添加sudo权限</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">root@c7f88304681b:/# groupadd -g <span style="color:#ae81ff">1000</span> spark
root@c7f88304681b:/# useradd -u <span style="color:#ae81ff">2000</span> -g spark -m -s /bin/bash spark <span style="color:#75715e"># -m表示自动创建用户家目录/home/spark、并指定默认的登录shell为bash</span>
root@c7f88304681b:/# passwd spark                    <span style="color:#75715e">#给spark用户设置密码</span>
root@c7f88304681b:/# usermod -G sudo spark           <span style="color:#75715e">#为spark用户添加sudo权限</span>
</code></pre></div><p>之后我们可以<strong>spark用户</strong>登录到slave1容器中：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">ubuntu# docker exec -it --user<span style="color:#f92672">=</span>spark slave1 bash
spark@c7f88304681b:~$
</code></pre></div><p>开启ssh服务：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">root@c7f88304681b:/# /etc/init.d/ssh start
</code></pre></div><p>编辑<code>/etc/ssh/sshd_config</code>, 允许公钥登录</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">PubkeyAuthentication yes
AuthorizedKeysFile      .ssh/authorized_keys 
</code></pre></div><p>然后将master和slave1、slave2的公钥都放入<code>authorized_keys</code>中，分发到三个系统的~/.ssh/目录下，即可互相之间免密码登录：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e">#演示免登录</span>
spark@master $ ssh spark@slave1
Welcome to Ubuntu 18.04.5 LTS <span style="color:#f92672">(</span>GNU/Linux 5.4.0-62-generic x86_64<span style="color:#f92672">)</span>
.....
Last login: Sun Jan <span style="color:#ae81ff">24</span> 09:20:10 <span style="color:#ae81ff">2021</span> from 172.17.0.1
$ 
<span style="color:#75715e"># ....</span>
spark@master $ ssh spark@slave2
Welcome to Ubuntu 18.04.5 LTS <span style="color:#f92672">(</span>GNU/Linux 5.4.0-62-generic x86_64<span style="color:#f92672">)</span>
.....
Last login: Sun Jan <span style="color:#ae81ff">24</span> 09:20:18 <span style="color:#ae81ff">2021</span> from 172.17.0.1
$ 
</code></pre></div><p>为了达到上面的登录时，不用输入ip的目的，还需要在<code>/etc/hosts</code>文件中添加以下ip和名称的映射关系</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">172.17.0.2   master
172.17.0.3   slave1
172.17.0.4   slave2
</code></pre></div><h2 id="hadoopspark">容器中安装hadoop、spark</h2>
<p>在用户主机上执行（自行下载jdk、maven、scala、hadoop、spark等安装包）：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># 将安装包从用户主机复制到master、slave1和slave2中</span>
$sudo docker cp ./OpenJDK8U-jdk_x64_linux_hotspot_8u275b01.tar.gz slave1:/app/soft/
$sudo docker cp ./hadoop-3.3.0.tar.gz slave1:/app/soft/
$sudo docker cp ./spark-3.0.1.tgz slave1:/app/soft/
</code></pre></div><p>登录slave1：安装jdk、hadoop、spark</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">spark@slave1:/app/soft$ tar -xvzf OpenJDK8U-jdk_x64_linux_hotspot_8u275b01.tar.gz
spark@slave1:/app/soft$ tar -xvzf hadoop-3.3.0.tar.gz
spark@slave1:/app/soft$ tar -xvzf spark-3.0.1.tgz
</code></pre></div><p>配置环境变量，<code>~/.bashrc</code>中添加：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">export JAVA_HOME<span style="color:#f92672">=</span>/app/soft/jdk8u275-b01
export HADOOP_HOME<span style="color:#f92672">=</span>/app/soft/hadoop-3.3.0
export YARN_HOME<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>HADOOP_HOME<span style="color:#e6db74">}</span>
export HADOOP_CONF_DIR<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>HADOOP_HOME<span style="color:#e6db74">}</span>/conf
export CLASSPATH<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>JAVA_HOME<span style="color:#e6db74">}</span>/lib/dt.jar:<span style="color:#e6db74">${</span>JAVA_HOME<span style="color:#e6db74">}</span>/lib/tools.jar
export SPARK_HOME<span style="color:#f92672">=</span>/app/soft/spark-3.0.1
export PATH<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>JAVA_HOME<span style="color:#e6db74">}</span>/bin:<span style="color:#e6db74">${</span>HADOOP_HOME<span style="color:#e6db74">}</span>/bin:<span style="color:#e6db74">${</span>HADOOP_HOME<span style="color:#e6db74">}</span>/sbin:<span style="color:#e6db74">${</span>SPARK_HOME<span style="color:#e6db74">}</span>/bin:<span style="color:#e6db74">${</span>SPARK_HOME<span style="color:#e6db74">}</span>/sbin:$PATH
</code></pre></div><h1 id="heading-2">配置文件</h1>
<ul>
<li>hadoop-env.sh 环境变量（指定JAVA_HOME）</li>
<li>core-site.xml、hdfs-site.xml</li>
<li>yarn-site.xml、mapre-site.xml、capacity-scheduler.xml</li>
<li>log4j.properties 日志</li>
</ul>
<h2 id="hdfs">hdfs</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># hadoop-env.sh</span>
export JAVA_HOME<span style="color:#f92672">=</span>/app/soft/jdk8u275-b01
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-xml" data-lang="xml"><span style="color:#75715e">&lt;!--</span><span style="color:#75715e"> core</span><span style="color:#75715e">-</span><span style="color:#75715e">site.xml </span><span style="color:#75715e">--&gt;</span>
<span style="color:#f92672">&lt;configuration</span><span style="color:#f92672">&gt;</span>
  <span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
      <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>fs.defaultFS<span style="color:#f92672">&lt;/name&gt;</span>
      <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>hdfs://master:9000<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>
  <span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
    <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>hadoop.tmp.dir<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>/usr/local/tmp/spark<span style="color:#f92672">&lt;/value&gt;</span>
    <span style="color:#f92672">&lt;description</span><span style="color:#f92672">&gt;</span>A base for other temporary directories.<span style="color:#f92672">&lt;/description&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>
<span style="color:#f92672">&lt;/configuration&gt;</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-xml" data-lang="xml"><span style="color:#75715e">&lt;!--</span><span style="color:#75715e"> hdfs</span><span style="color:#75715e">-</span><span style="color:#75715e">site.xml </span><span style="color:#75715e">--&gt;</span>
<span style="color:#f92672">&lt;configuration</span><span style="color:#f92672">&gt;</span>
  <span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
        <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>dfs.replication<span style="color:#f92672">&lt;/name&gt;</span>
        <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>3<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>
  <span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
    <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>dfs.namenode.name.dir<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>file:/usr/local/tmp/spark/dfs/name<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>
  <span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
    <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>dfs.datanode.data.dir<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>file:/usr/local/tmp/spark/dfs/data<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>
<span style="color:#f92672">&lt;/configuration&gt;</span>
</code></pre></div><h2 id="yarn">yarn</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-xml" data-lang="xml"><span style="color:#75715e">&lt;!--</span><span style="color:#75715e"> yarn</span><span style="color:#75715e">-</span><span style="color:#75715e">site.xml </span><span style="color:#75715e">--&gt;</span>
<span style="color:#f92672">&lt;configuration</span><span style="color:#f92672">&gt;</span>
  <span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
    <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>yarn.resourcemanager.hostname<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>master<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>
  <span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
    <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>yarn.nodemanager.aux-services<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>mapreduce_shuffle<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>
  <span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
    <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>yarn.resourcemanager.address<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>master:8032<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>
  <span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
    <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>yarn.resourcemanager.scheduler.address<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>master:8030<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>
  <span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
    <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>yarn.resourcemanager.resource-tracker.address<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>master:8031<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>
  <span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
    <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>yarn.resourcemanager.scheduler.class<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>
  <span style="color:#f92672">&lt;property</span><span style="color:#f92672">&gt;</span>
    <span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>yarn.nodemanager.env-whitelist<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;value</span><span style="color:#f92672">&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>
<span style="color:#f92672">&lt;/configuration&gt;</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># workers</span>
slave1
slave2
</code></pre></div><h2 id="spark">spark</h2>
<p>spark配置较简单，配置两个文件即可使用：<code>spark-env.sh、slaves</code>。</p>
<p><code>/app/soft/spark-3.0.1/conf/spark-env.sh</code>：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">export JAVA_HOME<span style="color:#f92672">=</span>/app/soft/jdk8u275-b01
export SPARK_HOME<span style="color:#f92672">=</span>/app/soft/spark-3.0.1
export HADOOP_HOME<span style="color:#f92672">=</span>/app/soft/hadoop-3.3.0
export HADOOP_CONF_DIR<span style="color:#f92672">=</span>/app/soft/hadoop-3.3.0/conf
export SPARK_DIST_CLASSPATH<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>$HADOOP_HOME/bin/hadoop classpath<span style="color:#66d9ef">)</span>
export SPARK_LOCAL_IP<span style="color:#f92672">=</span>172.17.0.2
export SPARK_MASTER_IP<span style="color:#f92672">=</span>master
export SPARK_MASTER_HOST<span style="color:#f92672">=</span>172.17.0.2 <span style="color:#75715e">#  HOST在启动slaves时会用到，不配置会启动不了worker</span>
export SPARK_MASTER_PORT<span style="color:#f92672">=</span>7077
export SPARK_EXECUTOR_INSTANCES<span style="color:#f92672">=</span>1
export SPARK_WORKER_INSTANCES<span style="color:#f92672">=</span>1
export SPARK_WORKER_CORES<span style="color:#f92672">=</span>1
export SPARK_WORKER_MEMORY<span style="color:#f92672">=</span>128M    <span style="color:#75715e"># 每个worker的内存配置为128M</span>
export SPARK_MASTER_WEBUI_PORT<span style="color:#f92672">=</span>8080
export SPAKR_CONF_DIR<span style="color:#f92672">=</span>/app/soft/spark-3.0.1/conf
</code></pre></div><p><code>/app/soft/spark-3.0.1/conf/slaves</code>：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">master
slave1
slave2
</code></pre></div><h1 id="heading-3">运行启动</h1>
<p>启动hdfs(namenode、datanode)：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">spark@4d0d1b1c25a0:~$ start-dfs.sh 
Starting namenodes on <span style="color:#f92672">[</span>master<span style="color:#f92672">]</span>
Starting datanodes
Starting secondary namenodes <span style="color:#f92672">[</span>4d0d1b1c25a0
</code></pre></div><p>打开浏览器：<code>http://master:9870</code>即可看到：</p>
<p><figure>
    <img src="/docs-pic/bigdata/hadoop_namenode.png" width="70%" height="50%"/> 
</figure>

<figure>
    <img src="/docs-pic/bigdata/hadoop_datanode.png" width="70%" height="50%"/> 
</figure>
</p>
<p>启动yarn：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">spark@4d0d1b1c25a0:~$ start-yarn.sh 
Starting resourcemanager
Starting nodemanagers
</code></pre></div><figure>
    <img src="/docs-pic/bigdata/yarn_manager.png" width="70%" height="50%"/> 
</figure>

<p>启动spark：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">spark@4d0d1b1c25a0:~$ start-master.sh 
starting org.apache.spark.deploy.master.Master, logging to /app/soft/spark-3.0.1/logs/spark--org.apache.spark.deploy.master.Master-1-4d0d1b1c25a0.out
spark@4d0d1b1c25a0:~$ start-slaves.sh 
slave1: starting org.apache.spark.deploy.worker.Worker, logging to /app/soft/spark-3.0.1/logs/spark-spark-org.apache.spark.deploy.worker.Worker-1-c7f88304681b.out
slave2: starting org.apache.spark.deploy.worker.Worker, logging to /app/soft/spark-3.0.1/logs/spark-spark-org.apache.spark.deploy.worker.Worker-1-d2e415d5d1ae.out
master: starting org.apache.spark.deploy.worker.Worker, logging to /app/soft/spark-3.0.1/logs/spark-spark-org.apache.spark.deploy.worker.Worker-1-4d0d1b1c25a0.out
</code></pre></div><figure>
    <img src="/docs-pic/bigdata/spark_master.png" width="70%" height="50%"/> 
</figure>

<p>顺便我们也可以在我们的master和slave上运行<code>jps</code>查看jvm中的进程：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># master上运行jps</span>
spark@4d0d1b1c25a0:~$ jps
<span style="color:#ae81ff">1648</span> Worker
<span style="color:#ae81ff">1699</span> Jps
<span style="color:#ae81ff">1127</span> ResourceManager
<span style="color:#ae81ff">647</span> NameNode
<span style="color:#ae81ff">1482</span> Master
<span style="color:#ae81ff">847</span> SecondaryNameNode
<span style="color:#75715e"># slave1上运行jps</span>
spark@c7f88304681b:/$ jps
<span style="color:#ae81ff">465</span> Worker
<span style="color:#ae81ff">178</span> DataNode
<span style="color:#ae81ff">291</span> NodeManager
<span style="color:#ae81ff">525</span> Jps
</code></pre></div><h1 id="heading-4">其余参考</h1>
<h2 id="ubuntu-1">配置ubuntu源</h2>
<p>ubuntu自带的apt源下载应用速度过慢，可以使用tsinghua、163、或者aliyun的源，这里以aliyun的源为例：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">spark$ su
root# mv /etc/apt/sources.list /etc/apt/sources.list.bak
root# touch /etc/apt/sources.list
</code></pre></div><p>编辑sources.list文件内容为：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse

deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse
</code></pre></div><p>之后别忘记<code>apt update</code>以下，就可以使用apt install 愉快的安装应用了。</p>
<h2 id="docker-2">docker命令</h2>
<p>由于docker是运行在用户主机上的，所以用户主机关机后，docker中的容器也会自动关掉。</p>
<p>可以通过<code>docker container restart slave1</code>命令启动slave1容器</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$ sudo docker container restart slave1
</code></pre></div><h2 id="linux">linux操作</h2>
<p>查看当前机器名称：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">spark@4d0d1b1c25a0:/$ cat /etc/hostname 
4d0d1b1c25a0
</code></pre></div></article>
    <footer class="post-footer">
      
      <ul class="post-tags">
        
          <li><a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE"><span class="tag">大数据</span></a></li>
        
          <li><a href="/tags/spark"><span class="tag">Spark</span></a></li>
        
          <li><a href="/tags/docker"><span class="tag">Docker</span></a></li>
        
      </ul>
      
      
      
<div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">L0phTg</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">2021-03-03</span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">许可协议</span>
    <span class="item-content">原创文章，如需转载请注明文章作者和出处。谢谢！</span>
  </p>
</div>
    </footer>
    
      
    
  </section>
  
  

  
  
  
<footer class="site-footer">
  <p>© 2017-2021 L0phTg&#39;s Blog</p>
  <p>Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> with theme <a href="https://github.com/laozhu/hugo-nuo" target="_blank" rel="noopener">Nuo</a>.</p>
  
</footer>


<script src="https://cdn.jsdelivr.net/npm/smooth-scroll@15.0.0/dist/smooth-scroll.min.js"></script>



<script async src="https://cdn.jsdelivr.net/npm/video.js@7.3.0/dist/video.min.js"></script>




<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[','\\]']],
      processEscapes: true,
      processEnvironments: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      TeX: { equationNumbers: { autoNumber: "AMS" },
      extensions: ["AMSmath.js", "AMSsymbols.js"] }
    },
  });
</script>
<script type="text/x-mathjax-config">
  // Fix <code> tags after MathJax finishes running. This is a
  // hack to overcome a shortcoming of Markdown. Discussion at
  // https://github.com/mojombo/jekyll/issues/199
  MathJax.Hub.Queue(() => {
    MathJax.Hub.getAllJax().map(v => v.SourceElement().parentNode.className += ' has-jax');
  });
</script>



<script src="/scripts/index.min.js"></script>

<script>
  if ('serviceWorker' in navigator) {
    navigator.serviceWorker.register('\/service-worker.js').then(function() {
      console.log('[ServiceWorker] Registered');
    });
  }
</script>








    
  </body>
</html>
